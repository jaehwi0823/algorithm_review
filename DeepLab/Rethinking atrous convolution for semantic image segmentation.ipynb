{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinkng Atrous Convolution for Semantic Image Segmentation - DeepLab v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "1. Reduced feature resolution caused by consecutive pooling or convolution strideing --> Atrous Convolution\n",
    "2. The existance of objects at multiple scales --> Image Pyramid + Encoder-decoder Structure + Atrous Conv. + Spatial Pyramid Pooling(SPP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Related Work\n",
    "\n",
    "### 2.1 Image Pyramid\n",
    "\n",
    "![Image_Pyramid.png](.\\Image_Pyramid.png)\n",
    "\n",
    "Feed each scale input to a DCNN and merge the feature maps from all the scales. Apply multi-scale inputs sequentially from coarse-to-fine.\n",
    "However, it doesn't scale well for larger/deeper DCNNs due to limited GPU.\n",
    "\n",
    "1. From small scale inputs, the long-range context\n",
    "2. From large scale inputs, the small objects details"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Encoder - decoder\n",
    "\n",
    "![Encoder_Decoder.png](.\\Encoder_Decoder.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Context module\n",
    "\n",
    "Encoding long-range context. <br>\n",
    "One effective method is to incorporate **DenseCRF**.\n",
    "\n",
    "![DenseCRF.jpeg](.\\DenseCRF.jpeg)\n",
    "<center>[Image reference](http://slideplayer.com/slide/784090/)</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Spatial Pyramid Pooling (SPP)\n",
    "\n",
    "\n",
    "![SPP.png](.\\SPP.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Atrous Convolution(Dilated Conv)\n",
    "\n",
    "Atrous Convolution: powerful tool to \n",
    "    1. explicitly adjust filter's field of view \n",
    "    2. control the resolution of feature responses computed by DCNN\n",
    "\n",
    "![Atrous_detail.png](.\\Atrous_detail.png)\n",
    "\n",
    "![Dilated_Conv.png](.\\Dilated_Conv.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method\n",
    "### 3.1 Atrous Convolution for Dense Feature Extraction\n",
    "\n",
    "Atrous Conv.\n",
    "\n",
    "![Dilated_Conv2-1.png](.\\Dilated_Conv2-1.png)\n",
    "\n",
    "![Dilated_Conv2-2.png](.\\Dilated_Conv2-2.png)\n",
    "\n",
    "![Dilated_Conv2-3.png](.\\Dilated_Conv2-3.png)\n",
    "\n",
    "<center> [Image Reference](http://iamyoonkim.tistory.com/18) </center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Going Deeper with Atrous Conv.\n",
    "\n",
    "** Atrous Convolution **\n",
    "Control the [output_stride] with **atrous rate ** ** *r* **\n",
    "1. Duplicate several copies of the last ResNet block\n",
    "2. 3 x 3 conv except for the last one with stride 2\n",
    "\n",
    "![Figure3.png](.\\Figure3.png)\n",
    "\n",
    "** Multi-grid Method **\n",
    "<br> one block with multi-rate Atrous Conv Filters\n",
    "<br> EX) Multi_Grid = (1,2,4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Atrous Spatial Pyramid Pooling(ASPP)\n",
    "\n",
    "ASPP is effectively captures multi-scale information\n",
    "\n",
    "![ASPP.png](.\\ASPP.png)\n",
    "![ASPP_DeepLab.png](.\\ASPP_DeepLab.png)\n",
    "\n",
    "<h4> * Problem </h4>\n",
    "As the sampling rate becomes larger, the number of valid filter weights becomes smaller. \n",
    "<br>valid weights: ???\n",
    "\n",
    "![Figure4.png](.\\Figure4.png)\n",
    "\n",
    "<h4> * Solution </h4>\n",
    "1. Apply global average pooling on the last feature map of the model\n",
    "2. Feed the resulting image-level features (&BN) to a 1x1 conv with 256 filters\n",
    "3. Bilinearly upsample the feature to the desired spatial dimension\n",
    "\n",
    "![Figure5.png](.\\Figure5.png)\n",
    "\n",
    "<h4> * Related Code </h4>\n",
    "![ASPP_Structure.png](.\\ASPP_Structure.png)\n",
    "<center> [Image Reference](https://github.com/rishizek/tensorflow-deeplab-v3) </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
