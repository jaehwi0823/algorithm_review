{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Why Should I Trust You?\" Explaining the Predictions of Any Classifier\n",
    "\n",
    "2018.07.15. <br>\n",
    "Jaehwi Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "> _ML영역에서 인간이 하는 일도 중요한데.. 간과당하고 있다고 주장합니다._\n",
    "> - 모형을 직접 사용하고\n",
    "> - 모형을 프로덕트에 배치합니다.\n",
    "\n",
    "<br>\n",
    "> _모형에 대한 신뢰(trust)는 두 가지로 구별돼야 합다고 합니다._\n",
    "> - 모형의 개별 Prediction 결과\n",
    "> - 모형 자체\n",
    "\n",
    "<br>\n",
    "> _본 논문에서는 다음을 제공합니다._\n",
    "> - 개별 Prediction에 대한 설명\n",
    "> - 모형 전체를 대표할 수 있는 유의미한 Instance를 선택하는 방법과 그에 대한 설명\n",
    "\n",
    "<br>\n",
    "> _Main Contribution !!_\n",
    "> - LIME:  _Any Classifier or Regressor_의 예측에 대한 설명 알고리즘입니다. (by approximating it locally with an interpretable model)\n",
    "> - SP-LIME: 대표 Instances를 선택하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Case for Explanations\n",
    "\n",
    "Input과 Output(Prediction) 사이의 관계를 보여줄 때 질적 평가가 가능합니다. 그리고 모형에 대한 결과를 도메인 지식을 미리 가지고 있는 전문가가 납득할 수 있을 때, 모형에 대한 신뢰가 가능합니다.\n",
    "\n",
    "![Figure1](./Figure1.png)\n",
    "\n",
    "> _모형이 잘못될 수 있는 여지들입니다._\n",
    "> - Data Leakage: 중요한데 없거나 전혀 중요치 않은데 모형에서 heavily rely on\n",
    "> - Dataset Shift: training <-> test 간의 변화\n",
    "\n",
    "<br>\n",
    "> _Desired Characteristics for Explainers_\n",
    "> - Interpretable\n",
    "> - Local Fidelity\n",
    "> - Model-agnostic\n",
    "> - global perspective\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Local Interpretable Model-Agnostic Explanations (LIME)\n",
    "\n",
    "### 3.1 Interpretable Data Representations\n",
    "\n",
    "> 정말 Raw input과 인간이 이해할 수 있는 representations는 차이가 있습니다. <br>\n",
    "> 따라서 다음 두 개는 구분이 필요합니다.\n",
    "> - features\n",
    "> - Interpretable Data Representations: 사람이 이해할 수 있는 features의 조합\n",
    "\n",
    "<br>\n",
    "> Notation\n",
    "> - Original representation of an instance: $x \\in \\mathbb{R}^d$\n",
    "> - interpretable representation: $x' \\in \\{0,1\\}^{d'}$  -> 특정 단어의 조합 또는 특정 patch의 유무(Binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fidelity - Interpretability Trade-off\n",
    "\n",
    "> - 설명을 모형 $g \\in G$로 합니다. G는 전통적인 해석가능한 모형을 의미합니다. (Linear Model, Decision Tree, or Falling Rule Lists)\n",
    "> - $g \\in G$의 도메인은 $\\{0,1\\}^{d'}$ 입니다. -> g가 \"interpretable components\"의 유무를 바탕으로 작동합니다.\n",
    "> - 모든 $g \\in G$가 해석가능하지 않으므로 $\\Omega (g)$로 g의 복잡도를 정의합니다. 복잡도가 증가하면 해석가능도가 떨어집니다.\n",
    ">> - Decision Tree라면 Node의 깊이가 복잡도에 해당하고\n",
    ">> - Linear Model의 경우는 Non-zero weights의 수가 복잡도에 해당할 것입니다.\n",
    "> - 설명할 모형 $f: \\mathbb{R}^d \\to \\mathbb{R}$\n",
    "> - 거리측도 from instance z to input x: $\\pi _x(z)$\n",
    "> - 설명모형 g가 unfaithful한 정도: $\\mathcal{L} (f,g,\\pi _x)$ -> 그러므로 minimize 해야함\n",
    "> - $\\xi (x) = argmin_{g \\in G} \\mathcal{L} (f,g,\\pi _x) + \\Omega (g)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Sampling for Local Exploration\n",
    "\n",
    "> - f에 상관없이 $\\mathcal{L} (f,g,\\pi _x)$를 최소화 하고 싶음\n",
    "> - $\\pi _x$에 가중치를 둔 샘플링으로 $\\mathcal{L} (f,g,\\pi _x)$를 근사합니다.\n",
    "> - nonzero elements of x'를 uniform random하게 뽑아서 z'를 만듭니다. (where the number of such draws is also uniformly sampled)\n",
    "> - $z' \\in \\{0,1\\} ^{d'}$를 다시 원래의 representation $z \\in R^d$로 돌려서 f(z)를 구합니다.\n",
    "> - 이러한 z'들 및 f(z)들의 결과(label) set을 가지고 위의 $\\xi (x)$를 최적화합니다.\n",
    "\n",
    "![Figure3](./Figure3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Sparse Linear Explanations\n",
    "\n",
    "![Algorithm1](Algorithm1.png)\n",
    "\n",
    "> - G를 Linear Model로 정의하면, $g(z') = w_g \\cdot z'$\n",
    "> - $\\pi _x(z) = exp(-D(x,z)^2/\\sigma ^2)$\n",
    ">> - $\\pi _x(z)$는 Exponential Kernel 입니다.\n",
    ">> - D는 Distance Function (cosine distance for text, L2 distance for Image)\n",
    ">> - $\\sigma$는 width입니다.\n",
    "> - $\\mathcal{L} (f,g,\\pi _x) = \\sum_{\\substack{z,z' \\in \\mathcal{Z}}} \\pi_x(z) (f(z) - g(z'))^2$\n",
    "> - 복잡도 정의\n",
    ">> - Text 분류에서는 단어들의 수 상한을 K로 정의함\n",
    ">> - Image에서는 \"super-pixels\"를 바탕으로 K개의 feature들을 LASSO 정규화를 통해 정의함\n",
    "![superpixel](./superpixel.png)\n",
    "> - 개별 Instance에 대한 해석이므로 Dataset 크기와는 무관하고, f(x) computing 시간 및 샘플 크기 N에 비례하여 시간이 소요된다.\n",
    "\n",
    "<br>\n",
    "> 단점 & Future Works\n",
    "> - interpretable representation이 충분히 강력하지 (적절치) 못할 수 있음. ex) super pixel로는 색의 영향 파악이 불가\n",
    "> - 모형이 매우매우매우 복잡하다면 선형설명기(G)로는 충분치 않을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submodular Pick for Explaining Models\n",
    "\n",
    "> - B instances 를 선별하여 모형 전체를 대변해보자 (Budget)\n",
    "> - global behavior를 이해하기 위해서는 _pick step_이 다양하고 모형을 대표하는 instance를 선별해야 한다.\n",
    "> - n개의 instance가 뽑히면, 최대 n x d'의 설명이 가능해진다.\n",
    ">> - instance $x_i$와 그에 대한 설명 $g_i = \\xi(x_i)$이 있을 때\n",
    ">> - 행렬 $\\mathcal{W}_{ij}= |w_{g_{ij}}|$ 생성이 가능하다.\n",
    ">> - 행렬 $\\mathcal{W}_{ij}$ 에서 열마다 Global Importance $I_j$를 계산할 수 있다.\n",
    "![Figure5](Figure5.png)\n",
    ">> - Text의 경우는 위 그림처럼 $I_j = \\sqrt{\\displaystyle\\sum_{i=1}^{n} \\mathcal{W}_{ij}}$\n",
    ">> - Image의 경우는 super-pixel간 비교할 수 있는 성질을 찾아야 하는데 ... remain future work ^^\n",
    "> - 아래의 알고리즘은 계산 복잡도가 NP-hard 이므로 Greedy Algorithm을 적용합니다.\n",
    "> ![Algorithm2](Algorithm2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
