{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating Object Instatnces with a Polygon-RNN\n",
    "\n",
    "<br> 2018.06.23\n",
    "<br> Jaehwi Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "> - The Goal of this paper is to make Annotating process faster and as precise as current datasets\n",
    "\n",
    "![F1](./Figure1.png)\n",
    "\n",
    "\n",
    "## 2. Related Work\n",
    "\n",
    "> - Semi-automatic annotation\n",
    "> - Annotation tools\n",
    "> - Object instance segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polygon-RNN\n",
    "\n",
    "> 1. Image representation via CNN\n",
    "> 2. Predict a vertex at every time step\n",
    "\n",
    "![F2](Figure2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Image Representation via a CNN with Skip Connections\n",
    "\n",
    "> - VGG-16 architecture\n",
    "> - No fully connected layers as well as the last max-pooling layer\n",
    "> - skip-connection !?\n",
    "> - all 3x3 kernel followed by a ReLU\n",
    "\n",
    "![vgg16](./vgg16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 RNN for Vertex Prediction\n",
    "\n",
    "> - two-layer __ConvLSTM__ with kernel size of 3x3 and 16 channels \n",
    "> - vertex prediction as a classification task\n",
    "> - Output: one-hot encoding of (DxD+1) grid\n",
    "> - (D x D + 1): possible 2D position of the vertex\n",
    "> - last one: The end-of-sequence token\n",
    "\n",
    "![ConvLSTM](./ConvLSTM.png)\n",
    "\n",
    "__ treat the first vertex as special __\n",
    "> - two layers after CNN encoder\n",
    "> - one branch predicts object boundaries\n",
    "> - the other takes boundaries + features => predicts the vertices of the polygon\n",
    "> - binary classification problem in each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training\n",
    "\n",
    "> - cross-entropy at each time step of the RNN\n",
    "> - smooth not to over penalize 근접한 결과 => ??\n",
    "\n",
    "__ first vertex __\n",
    "\n",
    "> - multi-task loss\n",
    "> - logistic loss for every location in the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Inference and Annotators in the Loop\n",
    "\n",
    "> - taking the vertex with the highest log-prob at each time step\n",
    "> - the annotator can correct the prediction at any time step => feed into the next time-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Implementation Details\n",
    "\n",
    "> - D = 28\n",
    "> - perform polygon simplification with zero error: \n",
    "<br>1. remove vertices on a line <br> 2. leave only one on a grid position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
